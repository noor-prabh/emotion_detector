# emotion_detector
This project uses deep learning and speech signal processing techniques to classify human emotions from audio recordings. It extracts MFCC features from speech data and trains a neural network model to recognize 8 different emotions. Achieves ~71% accuracy on the RAVDESS dataset.
